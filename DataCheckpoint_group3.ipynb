{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d060a5",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef44aa5e",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Mariam Bachar (A16217374)\n",
    "- Alexandra Hernandez (A16730685)\n",
    "- Brian Kwon (A16306826)\n",
    "- Andrew Uhm (A16729684)\n",
    "- Ethan Wang (A17229824)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270600d1",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e792a5",
   "metadata": {},
   "source": [
    "*Do certain keywords as identified by CLIP correlate with the popularity (as measured by the equivalent of “likes”) that artwork receives on social media?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c19bb8f",
   "metadata": {},
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ae5873",
   "metadata": {},
   "source": [
    "We predict that digital artwork that contains certain keywords as predicted by CLIP (painting vs. watercolor vs. digital) will indeed have a positive correlation to popularity on social media. As humans observing what is popular, we notice that certain features tend to repeat themselves across posts, which leads us to believe a correlation will be found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c1366",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01edecc4",
   "metadata": {},
   "source": [
    "Our ideal dataset would be a representative sample of images representing most genres of art. Our variables would be the image, the caption of an image, and their associated ‘likes’. We would want a decent amount of observations spanning that representative sample aforementioned, somewhere in the ballpark of ~3000 images alongside their “like” count and the original artist’s follow count. Files can be anonymized with integer IDs. From there, we would process the images to extract the captions using CLIP and store that to the corresponding data point’s image as well. Ideally images would all be the same size. Furthermore the ideal dataset would have published dates as well in order to make comparisons to past trends. In order to define popularity, we would define it as a number of likes in proportion to the maximum number of likes in our dataset, defining it regressively instead of binarily.\n",
    "\n",
    "A real data set we could use could be from DeviantArt’s API. We acknowledge that this data is different from our ideal. For one, the images are not perfectly square. We will thus crop and size the images down to a predetermined size (e.g. 768x768) in order to normalize. DeviantArt also likely has its own culture, which means our findings may not be representative of other social media and by taking images from their home page we may not be seeing old posts. Furthermore the fields that we require are actually optional, so we would have to filter to images that actually have all the data fields we require filled out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47d306",
   "metadata": {},
   "source": [
    "# Ethics and Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28db5e42",
   "metadata": {},
   "source": [
    "There are a number of ethical concerns regarding this research question that we must be mindful of as we analyze data. The most obvious issue is that we are tagging artwork as unpopular by virtue of not identifying said artwork as popular. However, this should not be a strong issue as we are not presenting identifying pieces of information of specific pieces of artwork or individual artists, so it should not be possible to label a specific artwork or artist as “unpopular”.\n",
    "\n",
    "In terms of normalization, a possible solution would be to take a ratio between the number of likes on the artwork and the number of followers that certain artist has in order to take into account the disparity between larger artists and smaller artists in terms of popularity, as more popular artists would get more likes due to a larger audience. Additionally, it is entirely possible that our analysis may exclude cultural influences of minority groups. Since those residing in developed countries have more leisure time/resources (such as drawing software or drawing e-tablets), it is plausible that most digital art posted to social media is likely from developed countries. Thus, the work we analyze may disproportionately represent artwork and cultural trends of majority groups of developed countries while glossing over minority groups, which tend to be similar across developed countries.\n",
    "\n",
    "Finally, because the artworks are on a public forum, they have consented to allowing their art to be analyzed. The Deviantart TOS states that you cannot “reproduce, distribute, publicly display or perform, or prepare derivative works”, which does not include the use of the artworks for an analytic survey. Although there is no clear-cut solution for this, it serves us well to keep this fact in mind when drawing conclusions upon our analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f04152",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e40258",
   "metadata": {},
   "source": [
    "- Dataset Name: deviation_info\n",
    "- Link to the dataset: https://github.com/COGS108/Group_Sp23_Project_Group_3/blob/master/deviation_info.csv\n",
    "- Number of observations: 1188\n",
    "\n",
    "This dataset is a set of deviations (that is images from deviantart) that contain deviation ids and metadata about the deviation itself as well as the author. It does not include the actual images.\n",
    "\n",
    "- Dataset Name: caption_info\n",
    "- Link to the dataset: https://github.com/COGS108/Group_Sp23_Project_Group_3/blob/master/caption_info.csv\n",
    "- Number of observations: 1188\n",
    "\n",
    "This dataset is a set of captions processed from the image, corresponding to a deviation id. It was processed using the CLIP interrogator in Automatic1111's stable diffusion webui.\n",
    "\n",
    "- Dataset Name: images\n",
    "- Link to the dataset: https://github.com/COGS108/Group_Sp23_Project_Group_3/tree/master/images\n",
    "- Number of observations: 1198\n",
    "\n",
    "This dataset is a directory of images in png format that are named based on their corresponding deviation ids, it is the actual images. There are 10 extra images in here that aren't found in our other datasets.\n",
    "\n",
    "\n",
    "All of the datasets were built from scraping, and use deviation ids as their identifiers. Because of this, we can easily add them together based on those deviation ids if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa97586",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bbeb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import deviantart\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# DeviantArt API: https://www.deviantart.com/developers/http/v1/20210526\n",
    "# Open-Source Python wrapper for DA API: https://github.com/neighbordog/deviantart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc52e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a pd df from the CSV file if it exists, else creates a blank df.\n",
    "csv_file = 'deviation_info.csv'\n",
    "try:\n",
    "    deviation_df = pd.read_csv(csv_file)\n",
    "except FileNotFoundError:\n",
    "    deviation_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b91714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate API keys in case of requesting issues.\n",
    "andrew_DA_API = deviantart.Api(\"25542\", \"61a232f232df245f2560a3cb72ecc535\")\n",
    "ethan_DA_API = deviantart.Api(\"25492\", \"06217cf59e73b401dc0a14d00857a793\")\n",
    "\n",
    "# access token is da.access_token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3761b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# README: use your own token\n",
    "cur_access = andrew_DA_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a36257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many images we want to fetch * 10\n",
    "n = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635c354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    print('on iteration', i, '* 10')\n",
    "    # grab 10 images at a time. DeviantArt calls their posts \"deviations\".\n",
    "    deviations = cur_access.browse(endpoint='popular', timerange='alltime', offset=i*10, limit=10)['results']\n",
    "    \n",
    "    for deviation in deviations:\n",
    "        # saves image to file by deviation id using url for local CLIP analysis\n",
    "        if deviation.content is None:\n",
    "            print('null deviation on iteration', i)\n",
    "            continue\n",
    "        url = deviation.content['src']\n",
    "        dId = deviation.deviationid\n",
    "        filename = f\"images/{dId}.png\"\n",
    "        path = Path(filename)\n",
    "        if path.is_file():\n",
    "            pass\n",
    "        else:\n",
    "            open(filename, 'w').close()\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "        \n",
    "        # these serve as examples of how to make a request when the python wrapper doesn't work\n",
    "        username = deviation.author.username\n",
    "        request = f\"https://www.deviantart.com/api/v1/oauth2/user/profile/{username}?access_token={cur_access.access_token}&expand=user.stats\"\n",
    "        response = requests.get(request)\n",
    "        authorData = response.json()\n",
    "        authorWatchers = authorData['user']['stats']['watchers']\n",
    "        authorPageViews = authorData['stats']['profile_pageviews'] # deemed unnecessary?\n",
    "        authorDeviations = authorData['stats']['user_deviations']\n",
    "        \n",
    "        request = f\"https://www.deviantart.com/api/v1/oauth2/deviation/metadata?access_token={cur_access.access_token}&deviationids={deviation}&ext_stats=True\"\n",
    "        response = requests.get(request)\n",
    "        metaData = response.json()\n",
    "        views = metaData['metadata'][0]['stats']['views']\n",
    "        \n",
    "        # gathering relevant data, turning it into a new observation.\n",
    "        row = {\n",
    "            'Deviation ID': deviation.deviationid,\n",
    "            'Title': deviation.title,\n",
    "            'Author': deviation.author,\n",
    "            'Views': views,\n",
    "            'Favorites': deviation.stats['favourites'],\n",
    "            'Comments': deviation.stats['comments'],\n",
    "            'URL Link': deviation.url,\n",
    "            'Date Posted': datetime.fromtimestamp(int(deviation.published_time)),\n",
    "            'Height': deviation.content['height'],\n",
    "            'Width': deviation.content['width'],\n",
    "            'File Size': deviation.content['filesize'],\n",
    "            'Author Watchers': authorWatchers,\n",
    "            'Author Page Views': authorPageViews,\n",
    "            'Author Deviations': authorDeviations\n",
    "        }\n",
    "        row_df = pd.DataFrame(row, index=[0])\n",
    "        deviation_df = pd.concat([deviation_df, row_df], ignore_index=True)\n",
    "        \n",
    "    # when running on the most popular posts, we will likely get duplicates. remove them.\n",
    "    deviation_df = deviation_df.drop_duplicates(subset='Deviation ID')\n",
    "    \n",
    "    # grab every 15 seconds in order to adhere to DeviantArt fetch rate.\n",
    "    if n > 1:\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc960b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put our dataframe into a CSV file so scraping can be collaborative.\n",
    "# to_csv overwrites but should be OK since we are reading from the CSV to populate the dataframe anyways.\n",
    "deviation_df.to_csv('deviation_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14867766",
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85210b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative clip interrogator.\n",
    "'''\n",
    "# https://github.com/pharmapsychotic/clip-interrogator\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from clip_interrogator import Config, Interrogator\n",
    "\n",
    "# setting up dataframe for captions.\n",
    "csv_file = 'caption_info.csv'\n",
    "try:\n",
    "    caption_df = pd.read_csv(csv_file)\n",
    "except FileNotFoundError:\n",
    "    caption_df = pd.DataFrame()\n",
    "\n",
    "# setting up interrogator\n",
    "ci = Interrogator(Config(clip_model_name=\"RN50/openai\"))\n",
    "\n",
    "subset_df = deviation_df[0:3]\n",
    "\n",
    "for deviation in subset_df.values:\n",
    "    dId = deviation[0]\n",
    "    image = Image.open(f\"images/{dId}.png\").convert('RGB')\n",
    "    \n",
    "    caption = ci.interrogate(image)\n",
    "    print(dId)\n",
    "    print(caption)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from PIL import Image\n",
    "import base64\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b952971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up dataframe for captions.\n",
    "csv_file = 'caption_info.csv'\n",
    "try:\n",
    "    caption_df = pd.read_csv(csv_file)\n",
    "except FileNotFoundError:\n",
    "    caption_df = pd.DataFrame()\n",
    "\n",
    "# this is so we can start farther down if we get an error.\n",
    "j = 700\n",
    "subset_df = deviation_df[j:]\n",
    "# save every n captions.\n",
    "n = 10\n",
    "\n",
    "i = 0\n",
    "for deviation in subset_df.values:\n",
    "    dId = deviation[0]\n",
    "    image = Image.open(f\"images/{dId}.png\")\n",
    "    \n",
    "    # https://www.reddit.com/r/StableDiffusion/comments/11f938k/using_automatic1111_apis_for_clip/\n",
    "    # https://stackoverflow.com/questions/52494592/wrong-colours-with-cv2-imdecode-python-opencv\n",
    "    # below converts image into string to pass through API.\n",
    "    # --------------------------------------------------------------\n",
    "    cv2_image = np.array(image)\n",
    "    cv2_image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)\n",
    "    _, buffer = cv2.imencode('.png', cv2_image)\n",
    "    input_image = base64.b64encode(buffer).decode('utf-8')\n",
    "\n",
    "    url = \"http://127.0.0.1:7860/sdapi/v1/interrogate\"\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    payload = {\n",
    "        \"image\": input_image,\n",
    "        \"model\": \"clip\"\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "    if response.status_code == 200:\n",
    "        caption = response.json()['caption']\n",
    "    else:\n",
    "        caption = \"NA\"\n",
    "    # ----------------------------------------------------------- after this, caption is the caption.\n",
    "    \n",
    "    # add info to caption dataframe.\n",
    "    row = {\n",
    "        'Deviation ID': dId,\n",
    "        'Caption': caption\n",
    "    }\n",
    "    row_df = pd.DataFrame(row, index=[0])\n",
    "    caption_df = pd.concat([caption_df, row_df], ignore_index=True)\n",
    "    \n",
    "    i+=1\n",
    "    if (i > n):\n",
    "        # write it out in case of crash, since it'll take a long time.\n",
    "        caption_df.to_csv('caption_info.csv', index=False)\n",
    "        i=0\n",
    "    j+=1\n",
    "    print(f\"Progress report: {j}\", end='\\r')\n",
    "\n",
    "# then save at the end regardless.\n",
    "caption_df = caption_df.drop_duplicates(subset='Deviation ID')\n",
    "caption_df.to_csv('caption_info.csv', index=False)\n",
    "print(\"\\nDone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_df = pd.read_csv('caption_info.csv')\n",
    "caption_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533bc734",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0133e3eb",
   "metadata": {},
   "source": [
    "Describe your data cleaning steps here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810eb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the .csv files which should have been created from the data gathering.\n",
    "deviation_df = pd.read_csv('deviation_info.csv')\n",
    "caption_df = pd.read_csv('caption_info.csv')\n",
    "\n",
    "# drop NA values if they exist in our deviation_df. Fortunately, all of our images have good values.\n",
    "print(deviation_df.shape)\n",
    "deviation_df = deviation_df.dropna()\n",
    "print(deviation_df.shape)\n",
    "\n",
    "# when a caption is failed to be read, it is given \"NA\" for a caption. Remove these from the list.\n",
    "# also if there is an NA then we drop it.\n",
    "print(caption_df.shape)\n",
    "caption_df = caption_df[caption_df['Caption'] != \"NA\"]\n",
    "caption_df = caption_df.dropna()\n",
    "print(caption_df.shape)\n",
    "\n",
    "# drop duplicates of both, just in case, although in our setup we already do this.\n",
    "deviation_df = deviation_df.drop_duplicates(subset='Deviation ID')\n",
    "caption_df = caption_df.drop_duplicates(subset='Deviation ID')\n",
    "\n",
    "# for the most part, our data is already clean."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
